{
  "model_file": "Llama-3.2-3B-Instruct-Q4_0.gguf",
  "model_path": "../../models/llms",
  "device": "gpu",
  "max_tokens": 50,
  "temperature": 0.7,
  "top_k": 40,
  "top_p": 0.9,
  "repeat_penalty": 1.18,
  "repeat_last_n": 64,
  "max_conversation_entries": 20,
  "active_context_size": 7
}